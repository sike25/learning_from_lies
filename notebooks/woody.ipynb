{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNyFlnAYW3SV+3Ip/Vxndfg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"tftoyrGcKcC7"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"ToWpY7niOlPR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Parameters\n","disk_epochs = 150\n","online_epochs = 50\n","epochs = online_epochs + disk_epochs\n","\n","warmup_steps = epochs // 4\n","eval_interval = 1 #epochs // 20\n","\n","noise_dim = 10\n","image_dim = 28\n","batch_size = 64\n","\n","max_translate = 3\n","max_rotation = 15\n","\n","target_accuracy = 0.98"],"metadata":{"id":"u9j75FiQOo1u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load MNIST and extract one sample per class\n","train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n","test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n","\n","base_images, base_labels = [], []\n","seen_classes = set()\n","for img, label in train_dataset:\n","    if label not in seen_classes:\n","        base_images.append(img)\n","        base_labels.append(label)\n","        seen_classes.add(label)\n","    if len(seen_classes) == 10:\n","        break\n","base_images = torch.stack(base_images, dim=0).to(device)\n","base_labels = torch.tensor(base_labels, dtype=torch.long).to(device)"],"metadata":{"id":"AHE3pp8vapGw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define Sampler MLP\n","class SamplerMLP(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(784 + noise_dim, 256),\n","            nn.LayerNorm(256),\n","            nn.ReLU(),\n","            nn.Linear(256, 128),\n","            nn.LayerNorm(128),\n","            nn.ReLU(),\n","            nn.Linear(128, 3)\n","        )\n","        self.net[-1].weight.data.uniform_(-0.1, 0.1)\n","        self.net[-1].bias.data.zero_()\n","\n","    def forward(self, x):\n","        params = self.net(x)\n","        return torch.stack([\n","            max_translate * torch.tanh(params[:, 0]),\n","            max_translate * torch.tanh(params[:, 1]),\n","            max_rotation * torch.tanh(params[:, 2]),\n","        ], dim=1)"],"metadata":{"id":"mRrQTTzLPBJJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define Classifier CNN\n","class ClassifierCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Conv2d(1, 8, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","\n","            nn.Conv2d(8, 16, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","\n","            nn.Flatten(),\n","            nn.Linear(16 * 7 * 7, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 10)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n"],"metadata":{"id":"YYCA2tjddRTW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Transformation function\n","def apply_transform(images, params, current_step):\n","    B = images.size(0)\n","    tx, ty, rot_deg = params[:, 0], params[:, 1], params[:, 2]\n","\n","    if warmup_steps > 0:\n","        progress = torch.tensor(current_step / warmup_steps, device=device).clamp(0, 1)\n","        tx = tx * progress\n","        ty = ty * progress\n","        rot_deg = rot_deg * progress\n","\n","    rot_rad = torch.deg2rad(rot_deg)\n","    cos, sin = torch.cos(rot_rad), torch.sin(rot_rad)\n","\n","    affine_mat = torch.zeros(B, 3, 3, device=device)\n","    affine_mat[:, 0, 0] = cos\n","    affine_mat[:, 0, 1] = -sin\n","    affine_mat[:, 1, 0] = sin\n","    affine_mat[:, 1, 1] = cos\n","    affine_mat[:, 0, 2] = tx / 14.0\n","    affine_mat[:, 1, 2] = ty / 14.0\n","    affine_mat[:, 2, 2] = 1.0\n","\n","    theta = torch.inverse(affine_mat)[:, :2, :]\n","    grid = F.affine_grid(theta, images.size(), align_corners=False)\n","    return F.grid_sample(images, grid, align_corners=False, padding_mode='border')"],"metadata":{"id":"UcCC8mV7fXoV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluation function\n","def evaluate(model):\n","    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    model.train()\n","    return correct / total"],"metadata":{"id":"MIlFGMnjgBmm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualization function\n","def visualize_augmentations(num_samples=5):\n","    sampler.eval()\n","    with torch.no_grad():\n","        fig, axs = plt.subplots(10, num_samples+1, figsize=(15, 25))\n","        for digit in range(10):\n","            img = base_images[digit].cpu().numpy().squeeze()\n","            axs[digit, 0].imshow(img, cmap='gray')\n","            axs[digit, 0].axis('off')\n","\n","            for i in range(num_samples):\n","                noise = torch.randn(1, noise_dim, device=device)\n","\n","                # We need to make them both 1D before concatenating:\n","                params = sampler(torch.cat([base_images[digit].flatten(), noise.flatten()], 0).unsqueeze(0))\n","\n","                # and then unsqueeze to add a batch dimension\n","                aug_img = apply_transform(base_images[digit].unsqueeze(0), params, online_epochs)  # Use max step for full transform\n","                axs[digit, i+1].imshow(aug_img.squeeze().cpu().numpy(), cmap='gray')\n","                axs[digit, i+1].axis('off')\n","        plt.tight_layout()\n","        plt.show()\n","    sampler.train()"],"metadata":{"id":"5sdRfSBgf80D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Online Training\n","\n","def online_training(epochs, warmup_steps, sampler, optimizer_s,\n","                    classifier, optimizer_c, scheduler_c, criterion):\n","\n","  print(\"Starting training with generated instances...\")\n","\n","  # Results\n","  loss_history     = []\n","  s_loss_history   = []\n","  accuracy_history = []\n","\n","  for step in range(1, epochs + 1):\n","\n","      # Phase 1: Train classifier\n","      idx = torch.randint(0, 10, (batch_size,), device=device)\n","      batch_images = base_images[idx]\n","      batch_labels = base_labels[idx]\n","      noise = torch.randn(batch_size, noise_dim, device=device)\n","\n","      with torch.no_grad():\n","          params = sampler(torch.cat([batch_images.view(batch_size, -1), noise], 1))\n","\n","      aug_images = apply_transform(batch_images, params, step)\n","\n","      optimizer_c.zero_grad()\n","      logits = classifier(aug_images)\n","      loss_c = criterion(logits, batch_labels)\n","      loss_c.backward()\n","      torch.nn.utils.clip_grad_norm_(classifier.parameters(), 1.0)\n","      optimizer_c.step()\n","      scheduler_c.step()\n","\n","      # Phase 2: Train sampler (after warmup)\n","      if step > warmup_steps:\n","          for p in classifier.parameters():\n","              p.requires_grad = False\n","\n","          params = sampler(torch.cat([batch_images.view(batch_size, -1), noise], 1))\n","          aug_images = apply_transform(batch_images, params, step)\n","          logits = classifier(aug_images)\n","          loss_s = -criterion(logits, batch_labels)\n","\n","          optimizer_s.zero_grad()\n","          loss_s.backward()\n","          torch.nn.utils.clip_grad_norm_(sampler.parameters(), 1.0)\n","          optimizer_s.step()\n","\n","          for p in classifier.parameters():\n","              p.requires_grad = True\n","      else:\n","          loss_s = torch.tensor(0.0)  # Dummy value during warmup\n","\n","      # evaluate loss and validation accuracy at intervals\n","      if step % eval_interval == 0:\n","          acc = evaluate(classifier)\n","          print(f\"Step {step:4d} | Class Loss: {loss_c.item():.4f} | Sampler Loss: {loss_s.item():.4f}\")\n","          print(f\"Test Accuracy: {acc*100:.2f}%\")\n","\n","          loss_history.append(loss_c.item())\n","          s_loss_history.append(loss_s.item())\n","          accuracy_history.append(acc)\n","\n","\n","  # TODO: Append final evaluation if eval_interval is not zero\n","\n","  return  accuracy_history, loss_history, s_loss_history"],"metadata":{"id":"53nBLhAH5QSn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run(startup_proportion, total_epochs):\n","\n","  # Initialize models and optimizers\n","  sampler = SamplerMLP().to(device)\n","  optimizer_s = torch.optim.Adam(sampler.parameters(), lr=1e-4)\n","\n","  classifier = ClassifierCNN().to(device)\n","  optimizer_c = torch.optim.Adam(classifier.parameters(), lr=3e-4)\n","  scheduler_c = torch.optim.lr_scheduler.OneCycleLR(optimizer_c, max_lr=3e-4, total_steps=online_epochs)\n","\n","  criterion = nn.CrossEntropyLoss()\n","\n","  # online training (start-up steps)\n","  online_epochs = startup_proportion * total_epochs\n","  accuracy_history, loss_history, s_loss_history = online_training(\n","      epochs, warmup_steps, sampler, optimizer_s,\n","      classifier, optimizer_c, scheduler_c, criterion)\n","\n","    # online training (start-up steps)\n","  online_epochs = startup_proportion * total_epochs\n","  accuracy_history, loss_history, s_loss_history = online_training(\n","      epochs, warmup_steps, sampler, optimizer_s,\n","      classifier, optimizer_c, scheduler_c, criterion)\n"],"metadata":{"id":"XlMrmPsz4rrW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["percentages = [round(0.1 * p, 2) for p in range(10)]\n","\n","for percent in percentages:\n","  run(percent)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2iNwXYjt2xXJ","executionInfo":{"status":"ok","timestamp":1745784798624,"user_tz":240,"elapsed":17,"user":{"displayName":"Osasikemwen Ogieva","userId":"10145887063794272442"}},"outputId":"6978fede-1af0-4158-d07d-853386c1f88d"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["## Experiment\n","\n","Vary X start-up epochs and Y regular epochs."],"metadata":{"id":"5J22FtLajSSd"}},{"cell_type":"code","source":["# Initialize models and optimizers\n","sampler = SamplerMLP().to(device)\n","optimizer_s = torch.optim.Adam(sampler.parameters(), lr=1e-4)\n","\n","classifier = ClassifierCNN().to(device)\n","optimizer_c = torch.optim.Adam(classifier.parameters(), lr=3e-4)\n","scheduler_c = torch.optim.lr_scheduler.OneCycleLR(optimizer_c, max_lr=3e-4, total_steps=online_epochs)\n","\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"sJgRTPLagIY8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### X - Startup Steps\n","\n","For the first X epochs, our pipeline doesn't use any data on disk, but uses generated instances to start up the model."],"metadata":{"id":"TZykPb88iR04"}},{"cell_type":"code","source":["# track epoch where we meet or surpass the target validation accuracy\n","target_epoch = 0\n","target_epoch_found = False"],"metadata":{"id":"3pybcBWunn8d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training loop\n","\n","print(\"Starting training with generated instances...\")\n","for step in range(1, online_epochs + 1):\n","\n","    # Phase 1: Train classifier\n","    idx = torch.randint(0, 10, (batch_size,), device=device)\n","    batch_images = base_images[idx]\n","    batch_labels = base_labels[idx]\n","    noise = torch.randn(batch_size, noise_dim, device=device)\n","\n","    with torch.no_grad():\n","        params = sampler(torch.cat([batch_images.view(batch_size, -1), noise], 1))\n","\n","    aug_images = apply_transform(batch_images, params, step)\n","\n","    optimizer_c.zero_grad()\n","    logits = classifier(aug_images)\n","    loss_c = criterion(logits, batch_labels)\n","    loss_c.backward()\n","    torch.nn.utils.clip_grad_norm_(classifier.parameters(), 1.0)\n","    optimizer_c.step()\n","    scheduler_c.step()\n","\n","    # Phase 2: Train sampler (after warmup)\n","    if step > warmup_steps:\n","        for p in classifier.parameters():\n","            p.requires_grad = False\n","\n","        params = sampler(torch.cat([batch_images.view(batch_size, -1), noise], 1))\n","        aug_images = apply_transform(batch_images, params, step)\n","        logits = classifier(aug_images)\n","        loss_s = -criterion(logits, batch_labels)\n","\n","        optimizer_s.zero_grad()\n","        loss_s.backward()\n","        torch.nn.utils.clip_grad_norm_(sampler.parameters(), 1.0)\n","        optimizer_s.step()\n","\n","        for p in classifier.parameters():\n","            p.requires_grad = True\n","    else:\n","        loss_s = torch.tensor(0.0)  # Dummy value during warmup\n","\n","    # Monitoring\n","    if step % 5 == 0:\n","        print(f\"Step {step:4d} | Class Loss: {loss_c.item():.4f} | Sampler Loss: {loss_s.item() if step>warmup_steps else 0:.4f}\")\n","\n","    # evaluate validation accuracy at intervals\n","    if step % eval_interval == 0:\n","        acc = evaluate(classifier)\n","        print(f\"Test Accuracy: {acc*100:.2f}%\")\n","        # visualize_augmentations()\n","\n","# Final evaluation\n","classifier.eval()\n","test_acc = evaluate(classifier)\n","print(f\"\\nFinal Test Accuracy: {test_acc*100:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vkhu53HAgaWG","executionInfo":{"status":"ok","timestamp":1745066828543,"user_tz":240,"elapsed":135155,"user":{"displayName":"Osasikemwen Ogieva","userId":"10145887063794272442"}},"outputId":"b8908e07-49d7-4eec-b7ce-c2dea78bff25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting training with generated instances...\n","Test Accuracy: 16.07%\n","Test Accuracy: 16.12%\n","Test Accuracy: 16.25%\n","Test Accuracy: 16.59%\n","Step    5 | Class Loss: 2.2792 | Sampler Loss: 0.0000\n","Test Accuracy: 16.97%\n","Test Accuracy: 17.55%\n","Test Accuracy: 17.99%\n","Test Accuracy: 18.35%\n","Test Accuracy: 18.57%\n","Step   10 | Class Loss: 2.2947 | Sampler Loss: 0.0000\n","Test Accuracy: 18.45%\n","Test Accuracy: 17.87%\n","Test Accuracy: 17.37%\n","Test Accuracy: 17.60%\n","Test Accuracy: 16.84%\n","Step   15 | Class Loss: 2.2968 | Sampler Loss: 0.0000\n","Test Accuracy: 15.54%\n","Test Accuracy: 15.24%\n","Test Accuracy: 15.37%\n","Test Accuracy: 15.02%\n","Test Accuracy: 16.49%\n","Step   20 | Class Loss: 2.2703 | Sampler Loss: 0.0000\n","Test Accuracy: 17.84%\n","Test Accuracy: 19.03%\n","Test Accuracy: 20.12%\n","Test Accuracy: 20.50%\n","Test Accuracy: 20.40%\n","Step   25 | Class Loss: 2.2511 | Sampler Loss: 0.0000\n","Test Accuracy: 20.31%\n","Test Accuracy: 20.28%\n","Test Accuracy: 20.40%\n","Test Accuracy: 20.49%\n","Test Accuracy: 20.58%\n","Step   30 | Class Loss: 2.2459 | Sampler Loss: 0.0000\n","Test Accuracy: 20.78%\n","Test Accuracy: 21.01%\n","Test Accuracy: 21.49%\n","Test Accuracy: 22.02%\n","Test Accuracy: 22.81%\n","Step   35 | Class Loss: 2.2109 | Sampler Loss: 0.0000\n","Test Accuracy: 23.80%\n","Test Accuracy: 24.35%\n","Test Accuracy: 25.21%\n","Test Accuracy: 25.93%\n","Test Accuracy: 26.43%\n","Step   40 | Class Loss: 2.2007 | Sampler Loss: 0.0000\n","Test Accuracy: 26.64%\n","Test Accuracy: 26.84%\n","Test Accuracy: 26.89%\n","Test Accuracy: 27.03%\n","Test Accuracy: 27.04%\n","Step   45 | Class Loss: 2.2108 | Sampler Loss: 0.0000\n","Test Accuracy: 26.99%\n","Test Accuracy: 27.00%\n","Test Accuracy: 27.00%\n","Test Accuracy: 27.00%\n","Test Accuracy: 27.00%\n","Step   50 | Class Loss: 2.2127 | Sampler Loss: 0.0000\n","Test Accuracy: 27.00%\n","\n","Final Test Accuracy: 27.00%\n"]}]},{"cell_type":"markdown","source":["### Y - Typical Supervision\n","\n","For the remaining Y epochs use the typical supervised learning data/pipeline."],"metadata":{"id":"KxAuL-TYitkP"}},{"cell_type":"code","source":["# Training loop (classic supervision)\n","\n","# load the training subset of the MNIST, reset scheduler\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","scheduler_c = torch.optim.lr_scheduler.OneCycleLR(optimizer_c, max_lr=3e-4, total_steps=disk_epochs)\n","\n","print(\"Starting the typical supervised training portion...\")\n","for step in range(1, disk_epochs + 1):\n","\n","    classifier.train()\n","    total_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for batch_images, batch_labels in train_loader:\n","\n","        batch_images = batch_images.to(device)\n","        batch_labels = batch_labels.to(device)\n","\n","        # Train just the classifier\n","        optimizer_c.zero_grad()\n","        logits = classifier(batch_images)\n","        loss_c = criterion(logits, batch_labels)\n","        loss_c.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(classifier.parameters(), 1.0)\n","        optimizer_c.step()\n","\n","        # evaluation metrics\n","        total_loss += loss_c.item() * batch_images.size(0)\n","        correct += (logits.argmax(dim=1) == batch_labels).sum().item()\n","        total += batch_images.size(0)\n","\n","    scheduler_c.step()\n","\n","    # Monitoring\n","    if step % 5 == 0:\n","        print(f\"Step {step:4d} | Classifier Loss: {loss_c.item():.4f} | Calculated Loss: {total_loss/total:.4f}\")\n","\n","    # evaluate validation accuracy at intervals\n","    if step % eval_interval == 0:\n","        acc = evaluate(classifier)\n","        print(f\"Test Accuracy: {acc*100:.2f}% | Validation Accuracy:  {correct/total*100:.2f}%\")\n","\n","        # monitor accuracy for when it crosses our target\n","        if acc >= target_accuracy and not target_epoch_found:\n","            target_epoch_found = True\n","            target_epoch = step\n","\n","    if target_epoch_found:break\n","\n","# Final evaluation\n","classifier.eval()\n","test_acc = evaluate(classifier)\n","print(f\"\\nFinal Test Accuracy: {test_acc*100:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvWyG6LNi1hs","executionInfo":{"status":"ok","timestamp":1745067376545,"user_tz":240,"elapsed":547994,"user":{"displayName":"Osasikemwen Ogieva","userId":"10145887063794272442"}},"outputId":"6aa319a0-86f8-42da-fb83-0624a277ddd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting the typical supervised training portion...\n","Test Accuracy: 57.29% | Validation Accuracy:  43.47%\n","Test Accuracy: 67.47% | Validation Accuracy:  61.43%\n","Test Accuracy: 78.22% | Validation Accuracy:  72.98%\n","Test Accuracy: 83.29% | Validation Accuracy:  80.05%\n","Step    5 | Classifier Loss: 0.4735 | Calculated Loss: 0.6078\n","Test Accuracy: 86.44% | Validation Accuracy:  83.95%\n","Test Accuracy: 88.75% | Validation Accuracy:  86.66%\n","Test Accuracy: 90.28% | Validation Accuracy:  88.77%\n","Test Accuracy: 91.48% | Validation Accuracy:  90.30%\n","Test Accuracy: 92.44% | Validation Accuracy:  91.51%\n","Step   10 | Classifier Loss: 0.2528 | Calculated Loss: 0.2570\n","Test Accuracy: 93.16% | Validation Accuracy:  92.54%\n","Test Accuracy: 94.11% | Validation Accuracy:  93.50%\n","Test Accuracy: 94.99% | Validation Accuracy:  94.41%\n","Test Accuracy: 95.53% | Validation Accuracy:  95.00%\n","Test Accuracy: 96.14% | Validation Accuracy:  95.67%\n","Step   15 | Classifier Loss: 0.3246 | Calculated Loss: 0.1295\n","Test Accuracy: 96.50% | Validation Accuracy:  96.25%\n","Test Accuracy: 96.70% | Validation Accuracy:  96.64%\n","Test Accuracy: 97.02% | Validation Accuracy:  96.92%\n","Test Accuracy: 97.32% | Validation Accuracy:  97.24%\n","Test Accuracy: 97.44% | Validation Accuracy:  97.41%\n","Step   20 | Classifier Loss: 0.1535 | Calculated Loss: 0.0799\n","Test Accuracy: 97.73% | Validation Accuracy:  97.59%\n","Test Accuracy: 97.54% | Validation Accuracy:  97.74%\n","Test Accuracy: 97.77% | Validation Accuracy:  97.89%\n","Test Accuracy: 98.03% | Validation Accuracy:  98.06%\n","\n","Final Test Accuracy: 98.03%\n"]}]},{"cell_type":"markdown","source":["## Control\n","\n","X + Y (all) epochs on classic supervision"],"metadata":{"id":"w9Nouzhdi5Ef"}},{"cell_type":"code","source":["# Initialize model and optimizer\n","control_classifier = ClassifierCNN().to(device)\n","control_optimizer  = torch.optim.Adam(control_classifier.parameters(), lr=3e-4)\n","control_scheduler  = torch.optim.lr_scheduler.OneCycleLR(control_optimizer, max_lr=3e-4, total_steps=epochs)"],"metadata":{"id":"pd8KVdEMjghg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# track epoch where we meet or surpass the target validation accuracy\n","control_target_epoch = 0\n","target_epoch_found = False"],"metadata":{"id":"AasZkl1rimIB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train\n","\n","# load the training subset of the MNIST\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","print(\"Starting classic supervised training...\")\n","for step in range(1, epochs + 1):\n","\n","    control_classifier.train()\n","    total_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for batch_images, batch_labels in train_loader:\n","\n","        batch_images = batch_images.to(device)\n","        batch_labels = batch_labels.to(device)\n","\n","        # Train just the classifier\n","        control_optimizer.zero_grad()\n","        logits = control_classifier(batch_images)\n","        loss = criterion(logits, batch_labels)\n","        loss .backward()\n","\n","        torch.nn.utils.clip_grad_norm_(control_classifier.parameters(), 1.0)\n","        control_optimizer.step()\n","\n","        # evaluation metrics\n","        total_loss += loss.item() * batch_images.size(0)\n","        correct += (logits.argmax(dim=1) == batch_labels).sum().item()\n","        total += batch_images.size(0)\n","\n","    control_scheduler.step()\n","\n","    # Monitoring\n","    if step % 5 == 0:\n","        print(f\"Step {step:4d} | Classifier Loss: {loss.item():.4f} | Calculated Loss: {total_loss/total:.4f}\")\n","\n","    # evaluate validation accuracy at intervals\n","    if step % eval_interval == 0:\n","        acc = evaluate(control_classifier)\n","        print(f\"Test Accuracy: {acc*100:.2f}% | Validation Accuracy:  {correct/total*100:.2f}%\")\n","\n","        # monitor accuracy for when it crosses our target\n","        if acc >= target_accuracy and not target_epoch_found:\n","            target_epoch_found = True\n","            control_target_epoch = step\n","\n","    if target_epoch_found:\n","      break\n","\n","# Final evaluation\n","control_classifier.eval()\n","test_acc = evaluate(control_classifier)\n","print(f\"\\nFinal Test Accuracy: {test_acc*100:.2f}%\")"],"metadata":{"id":"5Rd7ZDLwhsM8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Comparisons"],"metadata":{"id":"nKk7qs6sk3JX"}},{"cell_type":"code","source":["target_epoch, control_target_epoch"],"metadata":{"id":"oD5uVCKWk9Xk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VNO93vjHFZS_"},"execution_count":null,"outputs":[]}]}